{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": "from __future__ import division\n\nimport gym\nimport numpy as np\nimport random\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline", "cell_type": "code", "execution_count": 1, "outputs": [], "metadata": {"trusted": false}}, {"source": "env = gym.make('FrozenLake-v0')", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {"trusted": false}}, {"source": "tf.reset_default_graph()", "cell_type": "code", "execution_count": 3, "outputs": [], "metadata": {"trusted": false}}, {"source": "#These lines establish the feed-forward part of the network used to choose actions\ninputs1 = tf.placeholder(shape=[1,16],dtype=tf.float32)\nW = tf.Variable(tf.random_uniform([16,4],0,0.01))\nQout = tf.matmul(inputs1,W)\npredict = tf.argmax(Qout,1)\n\n#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\nnextQ = tf.placeholder(shape=[1,4],dtype=tf.float32)\nloss = tf.reduce_sum(tf.square(nextQ - Qout))\ntrainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\nupdateModel = trainer.minimize(loss)", "cell_type": "code", "execution_count": 4, "outputs": [], "metadata": {"scrolled": false, "trusted": false}}, {"source": "init = tf.global_variables_initializer()\n\n# Set learning parameters\ny = .99\ne = 0.1\nnum_episodes = 2000\n#create lists to contain total rewards and steps per episode\njList = []\nrList = []\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in range(num_episodes):\n        #Reset environment and get first new observation\n        s = env.reset()\n        rAll = 0\n        d = False\n        j = 0\n        #The Q-Network\n        while j < 99:\n            j+=1\n            #Choose an action by greedily (with e chance of random action) from the Q-network\n            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:np.identity(16)[s:s+1]})\n            if np.random.rand(1) < e:\n                a[0] = env.action_space.sample()\n            #Get new state and reward from environment\n            s1,r,d,_ = env.step(a[0])\n            #Obtain the Q' values by feeding the new state through our network\n            Q1 = sess.run(Qout,feed_dict={inputs1:np.identity(16)[s1:s1+1]})\n            #Obtain maxQ' and set our target value for chosen action.\n            maxQ1 = np.max(Q1)\n            targetQ = allQ\n            targetQ[0,a[0]] = r + y*maxQ1\n            #Train our network using target and predicted Q values\n            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:np.identity(16)[s:s+1],nextQ:targetQ})\n            rAll += r\n            s = s1\n            if d == True:\n                #Reduce chance of random action as we train the model.\n                e = 1./((i/50) + 10)\n                break\n        jList.append(j)\n        rList.append(rAll)\nprint(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")", "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Percent of succesful episodes: 0.001%\n"}], "metadata": {"trusted": false}}, {"source": "plt.plot(rList)", "cell_type": "code", "execution_count": 7, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[<matplotlib.lines.Line2D at 0x7ff821943250>]"}, "execution_count": 7}, {"output_type": "display_data", "data": {"image/png": "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\n", "text/plain": "<Figure size 432x288 with 1 Axes>"}, "metadata": {}}], "metadata": {"trusted": false}}, {"source": "import tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n\nn_nodes_hl1 = 500\nn_nodes_hl2 = 500\nn_nodes_hl3 = 500\nn_nodes_hl4 = 500\n\nn_classes = 10\nbatch_size = 100\n\nx = tf.placeholder('float', [None, 784])\ny = tf.placeholder('float')\n\ndef print_shape(obj):\n    print(obj.get_shape().as_list())\n\ndef neural_network_model(data):\n    hidden_1_layer = {'weights': tf.Variable(tf.random_normal([784,\n                                                               n_nodes_hl1])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl1]))}\n\n    hidden_2_layer = {'weights':\n                      tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl2]))}\n\n    hidden_3_layer = {'weights':\n                      tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl3]))}\n    \n    hidden_4_layer = {'weights':\n                      tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl4])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl4]))}\n\n    output_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl4,\n                                                             n_classes])),\n                    'biases': tf.Variable(tf.random_normal([n_classes]))}\n    print_shape(data)\n    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']),\n                hidden_1_layer['biases'])\n    print_shape(l1)\n    l1 = tf.nn.relu(l1)\n    print_shape(l1)\n    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']),\n                hidden_2_layer['biases'])\n    l2 = tf.nn.relu(l2)\n\n    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']),\n                hidden_3_layer['biases'])\n    l3 = tf.nn.relu(l3)\n\n    output = tf.add(tf.matmul(l3, output_layer['weights']),\n                    output_layer['biases'])\n    \n    l4 = tf.add(tf.matmul(l3, hidden_4_layer['weights']),\n               hidden_4_layer['biases'])\n    l4 = tf.nn.relu(l4)    \n\n    output = tf.add(tf.matmul(l4, output_layer['weights']),\n                   output_layer['biases'])\n    return output\n\n\ndef train_neural_network(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n                          (logits=prediction, labels=y))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n\n    hm_epochs = 10\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            for _ in range(int(mnist.train.num_examples / batch_size)):\n                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x,\n                                                              y: epoch_y})\n                epoch_loss += c\n            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:',\n                  epoch_loss)\n            \n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n        print('Accuracy:', accuracy.eval({x: mnist.test.images, y:\n                                          mnist.test.labels}))\n\n\ntrain_neural_network(x)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}, {"source": "def my_conv_net(input_data):\n    \n    batch_size = -1\n    learning_rate = 0.005\n    evaluation_size = 500\n#    image_width = ttrainData[0].shape[0]\n#    image_height = ttrainData[0].shape[1]\n    image_width = 16\n    image_height = 16\n#    target_size = max(ttrainLabels) + 1\n    num_channels = 1\n    generations = 500\n    eval_every = 5\n    conv1_features = 32\n    conv2_features = 64\n    max_pool_size1 = 2\n    max_pool_size2 = 2\n    fully_connected_size1 = 100\n    dropout_prob = 0.75\n    \n    # First Conv-ReLU-MaxPool Layer\n    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1, 1, 1, 1], padding='SAME')\n    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n    max_pool1 = tf.nn.max_pool(relu1, ksize=[1, max_pool_size1, max_pool_size1, 1], strides=[1, max_pool_size1, max_pool_size1, 1], padding='SAME')    \n    \n    print(\"input_data>>>: \", input_data)\n    print(\"conv1_weight>>>: \", conv1_weight)\n    print(\"conv1_weight get shape: \", conv1_weight.get_shape())\n    print(\"conv1_bias>>>: \", conv1_bias)\n    print(\"conv1>>>: \", conv1)\n    print(\"relu1>>>: \", relu1)\n    print(\"max_pool1>>>: \", max_pool1)\n    print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n\")\n    \n    # Second Conv-ReLU-MaxPool Layer\n    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1, 1, 1, 1], padding='SAME')\n    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n    max_pool2 = tf.nn.max_pool(relu2, ksize=[1, max_pool_size2, max_pool_size2, 1], strides=[1, max_pool_size2, max_pool_size2, 1], padding='SAME')\n    \n    print(\"conv2_weight>>>: \", conv2_weight)\n    print(\"conv2_bias>>>: \", conv2_bias)\n    print(\"conv2>>>: \", conv2)\n    print(\"relu2>>>: \", relu2)\n    print(\"max_pool2>>>: \", max_pool2)\n    print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n\")\n    \n    # Transform Output into a 1xN layer for next fully connected layer\n    final_conv_shape = max_pool2.get_shape().as_list()\n    final_shape = final_conv_shape[1] * final_conv_shape[2] * final_conv_shape[3]\n    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n    \n    # First Fully Connected Layer\n    print(\"flat_output ***: \", type(flat_output))\n    print(\"flat_output ***: \", flat_output)\n    print(\"full1_weight ***: \", type(full1_weight))\n    print(\"full1_weight ***: \", full1_weight)\n    print(\"full1_bias ***: \", type(full1_bias))\n    print(\"full1_bias ***: \", full1_bias)\n    \n    fully_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n    \n    # Second Fully Connected Layer\n    final_model = tf.add(tf.matmul(fully_connected1, full2_weight), full2_bias)\n    \n    # Add dropout\n    final_model_output = tf.nn.dropout(final_model, dropout)\n    \n    return(final_model_output)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}, {"source": "final_model_output", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}, {"source": "ttrainData type: <class 'numpy.ndarray'>\nttrainData shape: (279, 16, 16)\ntrain_data type: <class 'numpy.ndarray'>\nteval_dataArray shape: (120, 16, 16)\nttrainData[0]:  [[ 31.  30.  29. ...,  34.  41.  43.]\n [ 31.  31.  30. ...,  33.  38.  40.]\n [ 31.  32.  32. ...,  32.  37.  39.]\n ..., \n [ 26.  30.  37. ...,  48.  52.  54.]\n [ 32.  34.  39. ...,  45.  46.  45.]\n [ 42.  41.  42. ...,  45.  41.  37.]]\nttrainData[0]:  (16, 16)\nttestData[0]:  [[ 116.  101.   86. ...,   96.   89.   82.]\n [ 125.  111.   96. ...,   91.   86.   81.]\n [ 130.  119.  106. ...,   88.   87.   85.]\n ..., \n [ 120.  117.  116. ...,  107.  107.  111.]\n [ 123.  120.  120. ...,  115.  114.  118.]\n [ 126.  122.  122. ...,  121.  119.  123.]]\nttestData[0]:  (16, 16)\n$$$$$$$$$$$$$$$$$ checking1 $$$$$$$$$$$$$$$$$\n\nimage_width:  16\nimage_height:  16\nType of fully_connected_size1:  <class 'int'>\nfully_connected_size1 is:  100\nType of target_size:  <class 'numpy.float64'>\ntarget_size is:  2.0\n*********convert float to int 1st way:  2\n*********convert float to int:  <class 'int'>\n$$$$$$$$$$$$$$$$ checking2 $$$$$$$$$$$$$$$$$$$\n\nchecking3\nchecking4\nchecking5\ninput_data>>>:  Tensor(\"Placeholder_31:0\", shape=(-1, 16, 16, 1), dtype=float32)\nconv1_weight>>>:  Tensor(\"Variable/read:0\", shape=(4, 4, 1, 32), dtype=float32)\nconv1_weight get shape:  (4, 4, 1, 32)\nconv1_bias>>>:  Tensor(\"Variable_1/read:0\", shape=(32,), dtype=float32)\nconv1>>>:  Tensor(\"Conv2D_14:0\", shape=(100, 16, 16, 32), dtype=float32)\nrelu1>>>:  Tensor(\"Relu_20:0\", shape=(100, 16, 16, 32), dtype=float32)\nmax_pool1>>>:  Tensor(\"MaxPool_14:0\", shape=(100, 8, 8, 32), dtype=float32)\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nconv2_weight>>>:  Tensor(\"Variable_2/read:0\", shape=(4, 4, 32, 64), dtype=float32)\nconv2_bias>>>:  Tensor(\"Variable_3/read:0\", shape=(64,), dtype=float32)\nconv2>>>:  Tensor(\"Conv2D_15:0\", shape=(100, 8, 8, 64), dtype=float32)\nrelu2>>>:  Tensor(\"Relu_21:0\", shape=(100, 8, 8, 64), dtype=float32)\nmax_pool2>>>:  Tensor(\"MaxPool_15:0\", shape=(100, 4, 4, 64), dtype=float32)\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\nflat_output ***:  <class 'tensorflow.python.framework.ops.Tensor'>\nflat_output ***:  Tensor(\"Reshape_13:0\", shape=(1024, 100), dtype=float32)\nfull1_weight ***:  <class 'tensorflow.python.ops.variables.Variable'>\nfull1_weight ***:  Tensor(\"Variable_4/read:0\", shape=(3136, 100), dtype=float32)\nfull1_bias ***:  <class 'tensorflow.python.ops.variables.Variable'>\nfull1_bias ***:  Tensor(\"Variable_5/read:0\", shape=(100,), dtype=float32)\nTraceback (most recent call last):\n\n  File \"<ipython-input-22-1db506e814de>\", line 1, in <module>\n\n  \nValueError: Dimensions must be equal, but are 1024 and 3136 for 'MatMul_15' (op: 'MatMul') with input shapes: [100,1024], [3136,100]", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}, {"source": "def train_neural_network(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n                          (logits=prediction, labels=y))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n\n    hm_epochs = 10\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            for _ in range(int(mnist.train.num_examples / batch_size)):\n                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x,\n                                                              y: epoch_y})\n                epoch_loss += c\n            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:',\n                  epoch_loss)\n\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n        print('Accuracy:', accuracy.eval({x: mnist.test.images, y:\n                                          mnist.test.labels}))\n\n\ntrain_neural_network(x)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}, {"source": "def optimize_model():\n    if len(memory) < BATCH_SIZE:\n        return\n    transitions = memory.sample(BATCH_SIZE)\n    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n    # detailed explanation).\n    batch = Transition(*zip(*transitions))\n\n    # Compute a mask of non-final states and concatenate the batch elements\n    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n                                          batch.next_state)), device=device, dtype=torch.uint8)\n    non_final_next_states = torch.cat([s for s in batch.next_state\n                                                if s is not None])\n    state_batch = torch.cat(batch.state)\n    action_batch = torch.cat(batch.action)\n    reward_batch = torch.cat(batch.reward)\n\n    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n    # columns of actions taken\n    state_action_values = policy_net(state_batch).gather(1, action_batch)\n\n    # Compute V(s_{t+1}) for all next states.\n    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n    # Compute the expected Q values\n    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n\n    # Compute Huber loss\n    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n\n    # Optimize the model\n    optimizer.zero_grad()\n    loss.backward()\n    for param in policy_net.parameters():\n        param.grad.data.clamp_(-1, 1)\n    optimizer.step()\n\nnum_episodes = 50\nfor i_episode in range(num_episodes):\n    # Initialize the environment and state\n    env.reset()\n    last_screen = get_screen()\n    current_screen = get_screen()\n    state = current_screen - last_screen\n    for t in count():\n        # Select and perform an action\n        action = select_action(state)\n        _, reward, done, _ = env.step(action.item())\n        reward = torch.tensor([reward], device=device)\n\n        # Observe new state\n        last_screen = current_screen\n        current_screen = get_screen()\n        if not done:\n            next_state = current_screen - last_screen\n        else:\n            next_state = None\n\n        # Store the transition in memory\n        memory.push(state, action, next_state, reward)\n\n        # Move to the next state\n        state = next_state\n\n        # Perform one step of the optimization (on the target network)\n        optimize_model()\n        if done:\n            episode_durations.append(t + 1)\n            plot_durations()\n            break\n    # Update the target network\n    if i_episode % TARGET_UPDATE == 0:\n        target_net.load_state_dict(policy_net.state_dict())\n\nprint('Complete')\nenv.render()\nenv.close()\nplt.ioff()\nplt.show()", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython2", "version": "2.7.15", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}