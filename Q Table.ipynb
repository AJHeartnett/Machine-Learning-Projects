{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": "import gym\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {"trusted": false}}, {"source": "env = gym.make('FrozenLake-v0')", "cell_type": "code", "execution_count": 3, "outputs": [], "metadata": {"trusted": false}}, {"source": "#Initialize table with all zeros\nQ = np.zeros([env.observation_space.n,env.action_space.n])\n# Set learning parameters\nalpha = .8\ny = .95\nnum_episodes = 4000\n#create lists to contain total rewards and steps per episode\n#jList = []\nrList = []\nfor i in range(num_episodes):\n    #Reset environment and get first new observation\n    s = env.reset()\n    rAll = 0\n    d = False\n    j = 0\n    #The Q-Table learning algorithm\n    while j < 99:\n        j+=1\n        #Choose an action by greedily (with noise) picking from Q table\n        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n        #Get new state and reward from environment\n        s1,r,d,_ = env.step(a)\n        #Update Q-Table with new knowledge\n        Q[s,a] = Q[s,a] + alpha*(r + y*np.max(Q[s1,:]) - Q[s,a])\n        rAll += r\n        s = s1\n        if d == True:\n            break\n    #jList.append(j)\n    rList.append(rAll)", "cell_type": "code", "execution_count": 21, "outputs": [], "metadata": {"trusted": false}}, {"source": "print(\"Reward: \" +  str(sum(rList)/num_episodes))", "cell_type": "code", "execution_count": 22, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Reward: 0.5255\n"}], "metadata": {"trusted": false}}, {"source": "print(\"Final Q-Table Values\")\nprint(Q)", "cell_type": "code", "execution_count": 23, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Final Q-Table Values\n[[1.13682028e-01 8.35376863e-03 7.03668944e-03 8.40394050e-03]\n [4.55954881e-03 4.17135830e-03 4.60456745e-03 1.62926506e-01]\n [9.97782645e-02 1.28563942e-03 2.20165659e-03 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 1.96676976e-03 9.49573322e-03]\n [3.95687756e-01 8.30453457e-04 3.30855505e-03 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [7.03238019e-04 3.65963789e-06 1.19418641e-04 7.51683094e-06]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [0.00000000e+00 5.75523797e-03 0.00000000e+00 6.86983483e-01]\n [3.64657051e-03 2.87165237e-01 0.00000000e+00 0.00000000e+00]\n [7.82925788e-01 1.51870615e-04 4.27729922e-05 3.64602130e-04]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 5.88362704e-01 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.96873604e-01]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"}], "metadata": {"trusted": false}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": false}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython2", "version": "2.7.15", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}