{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": "from __future__ import division\n\nimport gym\nimport numpy as np\nimport random\nimport tensorflow as tf\n\nfrom gym.wrappers import Monitor\nimport itertools\nimport os\nimport sys\nimport psutil\n\nif \"../\" not in sys.path:\n  sys.path.append(\"../\")\n\n\nfrom collections import deque, namedtuple\nimport sklearn\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.python import *\nfrom tensorflow.python import pywrap_tensorflow\nhelp(pywrap_tensorflow)", "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Help on module tensorflow.python.pywrap_tensorflow in tensorflow.python:\n\nNAME\n    tensorflow.python.pywrap_tensorflow - A wrapper for TensorFlow SWIG-generated bindings.\n\nFILE\n    /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\n\nFUNCTIONS\n    AddControlInput(...)\n    \n    AddStep(...)\n    \n    AppendToFile(...)\n    \n    AssertSameStructure(...)\n    \n    Basename(...)\n    \n    BufferedInputStream_swigregister(...)\n    \n    CheckpointReader_GetTensor(...)\n    \n    CheckpointReader_swigregister(...)\n    \n    CleanPath(...)\n    \n    CopyFile(...)\n    \n    CreateBufferedInputStream(...)\n    \n    CreateDir(...)\n    \n    CreateURI(...)\n    \n    CreateWritableFile(...)\n    \n    CudaSupportsHalfMatMulAndConv(...)\n    \n    DeleteFile(...)\n    \n    DeleteProfiler(...)\n    \n    DeleteRecursively(...)\n    \n    Dirname(...)\n    \n    DoQuantizeTrainingOnGraphDefHelper(...)\n    \n    EqualAttrValueWrapper(...)\n    \n    EqualGraphDefWrapper(...)\n    \n    EventsWriter_swigregister(...)\n    \n    ExtendSession(...)\n    \n    Extension(...)\n    \n    FileExists(...)\n    \n    FileStatistics_swigregister(...)\n    \n    Flatten(...)\n    \n    GCluster_swigregister(...)\n    \n    GItem_swigregister(...)\n    \n    GenerateCostReport(...)\n    \n    GenerateModelReport(...)\n    \n    GetChildren(...)\n    \n    GetMatchingFiles(...)\n    \n    GetOperationInputs(...)\n    \n    GetPythonWrappers(...)\n    \n    GetTempFilename(...)\n    \n    InitializePyTrampoline(...)\n    \n    InstallStacktraceHandler(...)\n    \n    IsAbsolutePath(...)\n    \n    IsDirectory(...)\n    \n    IsGoogleCudaEnabled(...)\n    \n    IsMklEnabled(...)\n    \n    IsNamedtuple(...)\n    \n    IsSequence(...)\n    \n    ListDevices(...)\n    \n    ListDevicesWithSessionConfig(...)\n    \n    NewProfiler(...)\n    \n    ParseURI(...)\n    \n    PrintModelAnalysis(...)\n    \n    Profile(...)\n    \n    ProfilerFromFile(...)\n    \n    PyExceptionRegistry_Init(...)\n    \n    PyExceptionRegistry_swigregister(...)\n    \n    PyRecordReader_New(...)\n    \n    PyRecordReader_swigregister(...)\n    \n    PyRecordWriter_New(...)\n    \n    PyRecordWriter_swigregister(...)\n    \n    PyServer_Join(...)\n    \n    PyServer_New(...)\n    \n    PyServer_Start(...)\n    \n    PyServer_Stop(...)\n    \n    ReadFileToString(...)\n    \n    ReadFromStream(...)\n    \n    RecursivelyCreateDir(...)\n    \n    RegisterSequenceClass(...)\n    \n    RemoveAllControlInputs(...)\n    \n    RenameFile(...)\n    \n    ResourceHandleShapeAndType(...)\n    \n    RunCppShapeInference(...)\n    \n    SameNamedtuples(...)\n    \n    SerializeToString(...)\n    \n    ServerInterface_swigregister(...)\n    \n    SetAttr(...)\n    \n    SetRequestedDevice(...)\n    \n    SetRequireShapeInferenceFns(...)\n    \n    Set_TF_Status_from_Status(...)\n    \n    Stat(...)\n    \n    StatSummarizer_swigregister(...)\n    \n    StatusFromTF_Status(...)\n    \n    Status_OK(...)\n    \n    Status_swigregister(...)\n    \n    TFE_ContextAddFunction(...)\n    \n    TFE_ContextAddFunctionDef(...)\n    \n    TFE_ContextAsyncClearError(...)\n    \n    TFE_ContextAsyncWait(...)\n    \n    TFE_ContextClearCaches(...)\n    \n    TFE_ContextDisableRunMetadata(...)\n    \n    TFE_ContextEnableRunMetadata(...)\n    \n    TFE_ContextExportRunMetadata(...)\n    \n    TFE_ContextGetDevicePlacementPolicy(...)\n    \n    TFE_ContextListDevices(...)\n    \n    TFE_ContextOptionsSetAsync(...)\n    \n    TFE_ContextOptionsSetConfig(...)\n    \n    TFE_ContextOptionsSetDevicePlacementPolicy(...)\n    \n    TFE_ContextSetAsyncForThread(...)\n    \n    TFE_ContextSetThreadLocalDevicePlacementPolicy(...)\n    \n    TFE_DeleteContext(...)\n    \n    TFE_DeleteContextOptions(...)\n    \n    TFE_NewContext(...)\n    \n    TFE_NewContextOptions(...)\n    \n    TFE_OpNameGetAttrType(...)\n    \n    TFE_Py_Execute(...)\n    \n    TFE_Py_FastPathExecute(...)\n    \n    TFE_Py_InitEagerTensor(...)\n    \n    TFE_Py_RecordGradient(...)\n    \n    TFE_Py_RegisterBackwardFunctionGetter(...)\n    \n    TFE_Py_RegisterExceptionClass(...)\n    \n    TFE_Py_RegisterFallbackExceptionClass(...)\n    \n    TFE_Py_RegisterResourceVariableType(...)\n    \n    TFE_Py_TapeGradient(...)\n    \n    TFE_Py_TapeSetDeleteTrace(...)\n    \n    TFE_Py_TapeSetIsEmpty(...)\n    \n    TFE_Py_TapeSetNew(...)\n    \n    TFE_Py_TapeSetRecordOperation(...)\n    \n    TFE_Py_TapeSetRemove(...)\n    \n    TFE_Py_TapeSetRestartOnThread(...)\n    \n    TFE_Py_TapeSetShouldRecord(...)\n    \n    TFE_Py_TapeSetStopOnThread(...)\n    \n    TFE_Py_TapeSetWatch(...)\n    \n    TFE_Py_TapeSetWatchVariable(...)\n    \n    TFE_Py_TapeWatchedVariables(...)\n    \n    TFE_Py_TensorShapeSlice(...)\n    \n    TFE_Py_UID(...)\n    \n    TF_AddControlInput(...)\n    \n    TF_AddGradients(...)\n    \n    TF_AddInput(...)\n    \n    TF_AddInputList(...)\n    \n    TF_AllocateTensor(...)\n    \n    TF_ApiDefMapGet(...)\n    \n    TF_ApiDefMapPut(...)\n    \n    TF_AttrMetadata_swigregister(...)\n    \n    TF_Buffer_swigregister(...)\n    \n    TF_CloseDeprecatedSession(...)\n    \n    TF_CloseSession(...)\n    \n    TF_ColocateWith(...)\n    \n    TF_DataTypeSize(...)\n    \n    TF_DeleteApiDefMap(...)\n    \n    TF_DeleteBuffer(...)\n    \n    TF_DeleteDeprecatedSession(...)\n    \n    TF_DeleteDeviceList(...)\n    \n    TF_DeleteFunction(...)\n    \n    TF_DeleteGraph(...)\n    \n    TF_DeleteImportGraphDefOptions(...)\n    \n    TF_DeleteImportGraphDefResults(...)\n    \n    TF_DeleteLibraryHandle(...)\n    \n    TF_DeletePRunHandle(...)\n    \n    TF_DeleteSession(...)\n    \n    TF_DeleteSessionOptions(...)\n    \n    TF_DeleteStatus(...)\n    \n    TF_DeleteTensor(...)\n    \n    TF_DeprecatedSessionListDevices(...)\n    \n    TF_DeprecatedSessionMakeCallable(...)\n    \n    TF_DeprecatedSessionReleaseCallable(...)\n    \n    TF_DeprecatedSessionRunCallable(...)\n    \n    TF_DeterminePeakMemoryUsage(...)\n    \n    TF_DeviceListCount(...)\n    \n    TF_DeviceListMemoryBytes(...)\n    \n    TF_DeviceListName(...)\n    \n    TF_DeviceListType(...)\n    \n    TF_Dim(...)\n    \n    TF_EstimatePerformance(...)\n    \n    TF_ExtendGraph(...)\n    \n    TF_FinishOperation(...)\n    \n    TF_FunctionGetAttrValueProto(...)\n    \n    TF_FunctionImportFunctionDef(...)\n    \n    TF_FunctionSetAttrValueProto(...)\n    \n    TF_FunctionToFunctionDef(...)\n    \n    TF_GetAllOpList(...)\n    \n    TF_GetBuffer(...)\n    \n    TF_GetCode(...)\n    \n    TF_GetColocationGroups(...)\n    \n    TF_GetOpList(...)\n    \n    TF_GetOpProperties(...)\n    \n    TF_GetSupportedDevices(...)\n    \n    TF_GraphCopyFunction(...)\n    \n    TF_GraphGetFunctions(...)\n    \n    TF_GraphGetOpDef(...)\n    \n    TF_GraphGetTensorNumDims(...)\n    \n    TF_GraphGetTensorShape(...)\n    \n    TF_GraphGetTensorShapeHelper(...)\n    \n    TF_GraphImportGraphDef(...)\n    \n    TF_GraphImportGraphDefWithResults(...)\n    \n    TF_GraphImportGraphDefWithReturnOutputs(...)\n    \n    TF_GraphNextOperation(...)\n    \n    TF_GraphNumFunctions(...)\n    \n    TF_GraphOperationByName(...)\n    \n    TF_GraphSetOutputHandleShapesAndTypes_wrapper(...)\n    \n    TF_GraphSetTensorShape(...)\n    \n    TF_GraphSetTensorShape_wrapper(...)\n    \n    TF_GraphToFunction(...)\n    \n    TF_GraphToFunction_wrapper(...)\n    \n    TF_GraphToGraphDef(...)\n    \n    TF_GraphVersions(...)\n    \n    TF_IdentifyImportantOps(...)\n    \n    TF_ImportGraphDefOptionsAddControlDependency(...)\n    \n    TF_ImportGraphDefOptionsAddInputMapping(...)\n    \n    TF_ImportGraphDefOptionsAddReturnOperation(...)\n    \n    TF_ImportGraphDefOptionsAddReturnOutput(...)\n    \n    TF_ImportGraphDefOptionsNumReturnOperations(...)\n    \n    TF_ImportGraphDefOptionsNumReturnOutputs(...)\n    \n    TF_ImportGraphDefOptionsRemapControlDependency(...)\n    \n    TF_ImportGraphDefOptionsSetPrefix(...)\n    \n    TF_ImportGraphDefOptionsSetUniquifyNames(...)\n    \n    TF_ImportGraphDefOptionsSetUniquifyPrefix(...)\n    \n    TF_ImportGraphDefResultsMissingUnusedInputMappings_wrapper(...)\n    \n    TF_ImportGraphDefResultsReturnOperations(...)\n    \n    TF_ImportGraphDefResultsReturnOutputs(...)\n    \n    TF_Input_swigregister(...)\n    \n    TF_ListAvailableOps(...)\n    \n    TF_ListDevices(...)\n    \n    TF_LoadLibrary(...)\n    \n    TF_LoadSessionFromSavedModel(...)\n    \n    TF_MeasureCosts(...)\n    \n    TF_Message(...)\n    \n    TF_NewApiDefMap(...)\n    \n    TF_NewBuffer(...)\n    \n    TF_NewBufferFromString(...)\n    \n    TF_NewCluster(...)\n    \n    TF_NewDeprecatedSession(...)\n    \n    TF_NewGraph(...)\n    \n    TF_NewImportGraphDefOptions(...)\n    \n    TF_NewItem(...)\n    \n    TF_NewOperation(...)\n    \n    TF_NewSession(...)\n    \n    TF_NewStatus(...)\n    \n    TF_NewTensor(...)\n    \n    TF_NewVirtualCluster(...)\n    \n    TF_NumDims(...)\n    \n    TF_OperationDevice(...)\n    \n    TF_OperationGetAttrBool(...)\n    \n    TF_OperationGetAttrBoolList(...)\n    \n    TF_OperationGetAttrFloat(...)\n    \n    TF_OperationGetAttrFloatList(...)\n    \n    TF_OperationGetAttrInt(...)\n    \n    TF_OperationGetAttrIntList(...)\n    \n    TF_OperationGetAttrMetadata(...)\n    \n    TF_OperationGetAttrShape(...)\n    \n    TF_OperationGetAttrShapeList(...)\n    \n    TF_OperationGetAttrString(...)\n    \n    TF_OperationGetAttrStringList(...)\n    \n    TF_OperationGetAttrTensor(...)\n    \n    TF_OperationGetAttrTensorList(...)\n    \n    TF_OperationGetAttrTensorShapeProto(...)\n    \n    TF_OperationGetAttrTensorShapeProtoList(...)\n    \n    TF_OperationGetAttrType(...)\n    \n    TF_OperationGetAttrTypeList(...)\n    \n    TF_OperationGetAttrValueProto(...)\n    \n    TF_OperationGetControlInputs_wrapper(...)\n    \n    TF_OperationGetControlOutputs_wrapper(...)\n    \n    TF_OperationInput(...)\n    \n    TF_OperationInputListLength(...)\n    \n    TF_OperationInputType(...)\n    \n    TF_OperationName(...)\n    \n    TF_OperationNumControlInputs(...)\n    \n    TF_OperationNumControlOutputs(...)\n    \n    TF_OperationNumInputs(...)\n    \n    TF_OperationNumOutputs(...)\n    \n    TF_OperationOpType(...)\n    \n    TF_OperationOutputConsumers_wrapper(...)\n    \n    TF_OperationOutputListLength(...)\n    \n    TF_OperationOutputNumConsumers(...)\n    \n    TF_OperationOutputType(...)\n    \n    TF_OperationToNodeDef(...)\n    \n    TF_OptimizeGraph(...)\n    \n    TF_Output_swigregister(...)\n    \n    TF_PRun(...)\n    \n    TF_PRunSetup(...)\n    \n    TF_Reset_wrapper(...)\n    \n    TF_Run(...)\n    \n    TF_SessionListDevices(...)\n    \n    TF_SessionMakeCallable(...)\n    \n    TF_SessionPRunSetup_wrapper(...)\n    \n    TF_SessionPRun_wrapper(...)\n    \n    TF_SessionReleaseCallable(...)\n    \n    TF_SessionRunCallable(...)\n    \n    TF_SessionRun_wrapper(...)\n    \n    TF_SetAttrBool(...)\n    \n    TF_SetAttrBoolList(...)\n    \n    TF_SetAttrFloat(...)\n    \n    TF_SetAttrFloatList(...)\n    \n    TF_SetAttrFuncName(...)\n    \n    TF_SetAttrInt(...)\n    \n    TF_SetAttrIntList(...)\n    \n    TF_SetAttrShape(...)\n    \n    TF_SetAttrShapeList(...)\n    \n    TF_SetAttrString(...)\n    \n    TF_SetAttrStringList(...)\n    \n    TF_SetAttrTensor(...)\n    \n    TF_SetAttrTensorList(...)\n    \n    TF_SetAttrTensorShapeProto(...)\n    \n    TF_SetAttrTensorShapeProtoList(...)\n    \n    TF_SetAttrType(...)\n    \n    TF_SetAttrTypeList(...)\n    \n    TF_SetAttrValueProto(...)\n    \n    TF_SetDevice(...)\n    \n    TF_SetStatus(...)\n    \n    TF_ShutdownCluster(...)\n    \n    TF_StringDecode(...)\n    \n    TF_StringEncode(...)\n    \n    TF_StringEncodedSize(...)\n    \n    TF_TensorByteSize(...)\n    \n    TF_TensorData(...)\n    \n    TF_TensorMaybeMove(...)\n    \n    TF_TensorType(...)\n    \n    TF_TryEvaluateConstant(...)\n    \n    TF_TryEvaluateConstant_wrapper(...)\n    \n    TF_Version(...)\n    \n    TF_bfloat16_type(...)\n    \n    TfCheckOpHelper(...)\n    \n    TfCheckOpHelperOutOfLine(...)\n    \n    TransformGraphWithStringInputs(...)\n    \n    TryFindKernelClass(...)\n    \n    UpdateEdge(...)\n    \n    WritableFile_swigregister(...)\n    \n    WriteProfile(...)\n    \n    WriteStringToFile(...)\n\nDATA\n    GRAPH_DEF_VERSION = 26\n    GRAPH_DEF_VERSION_MIN_CONSUMER = 0\n    GRAPH_DEF_VERSION_MIN_PRODUCER = 0\n    SHARED_PTR_DISOWN = 0\n    TENSOR_HANDLE_KEY = 'TensorHandle'\n    TFE_DEVICE_PLACEMENT_EXPLICIT = 0\n    TFE_DEVICE_PLACEMENT_SILENT = 2\n    TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32 = 3\n    TFE_DEVICE_PLACEMENT_WARN = 1\n    TF_ABORTED = 10\n    TF_ALREADY_EXISTS = 6\n    TF_ATTR_BOOL = 3\n    TF_ATTR_FLOAT = 2\n    TF_ATTR_FUNC = 8\n    TF_ATTR_INT = 1\n    TF_ATTR_PLACEHOLDER = 7\n    TF_ATTR_SHAPE = 5\n    TF_ATTR_STRING = 0\n    TF_ATTR_TENSOR = 6\n    TF_ATTR_TYPE = 4\n    TF_BFLOAT16 = 14\n    TF_BOOL = 10\n    TF_CANCELLED = 1\n    TF_COMPLEX = 8\n    TF_COMPLEX128 = 18\n    TF_COMPLEX64 = 8\n    TF_DATA_LOSS = 15\n    TF_DEADLINE_EXCEEDED = 4\n    TF_DOUBLE = 2\n    TF_FAILED_PRECONDITION = 9\n    TF_FLOAT = 1\n    TF_HALF = 19\n    TF_INT16 = 5\n    TF_INT32 = 3\n    TF_INT64 = 9\n    TF_INT8 = 6\n    TF_INTERNAL = 13\n    TF_INVALID_ARGUMENT = 3\n    TF_NOT_FOUND = 5\n    TF_OK = 0\n    TF_OUT_OF_RANGE = 11\n    TF_PERMISSION_DENIED = 7\n    TF_QINT16 = 15\n    TF_QINT32 = 13\n    TF_QINT8 = 11\n    TF_QUINT16 = 16\n    TF_QUINT8 = 12\n    TF_RESOURCE = 20\n    TF_RESOURCE_EXHAUSTED = 8\n    TF_STRING = 7\n    TF_UINT16 = 17\n    TF_UINT32 = 22\n    TF_UINT64 = 23\n    TF_UINT8 = 4\n    TF_UNAUTHENTICATED = 16\n    TF_UNAVAILABLE = 14\n    TF_UNIMPLEMENTED = 12\n    TF_UNKNOWN = 2\n    TF_VARIANT = 21\n    __compiler_version__ = '4.8.4'\n    __cxx11_abi_flag__ = 0\n    __git_version__ = 'v1.8.0-0-g93bc2e2072'\n    __monolithic_build__ = 0\n    __version__ = '1.8.0'\n    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n\nVERSION\n    1.8.0\n\n\n"}], "metadata": {"trusted": true}}, {"source": "env = gym.make('FrozenLake-v0')", "cell_type": "code", "execution_count": 7, "outputs": [], "metadata": {"trusted": true}}, {"source": "import tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n\nn_nodes_hl1 = 500\nn_nodes_hl2 = 500\nn_nodes_hl3 = 500\nn_nodes_hl4 = 500\n\nn_classes = 10\nbatch_size = 100\n\nx = tf.placeholder('float', [None, 784])\ny = tf.placeholder('float')\n\ndef print_shape(obj):\n    print(obj.get_shape().as_list())\n\ndef neural_network_model(data):\n    hidden_1_layer = {'weights': tf.Variable(tf.random_normal([784,\n                                                               n_nodes_hl1])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl1]))}\n\n    hidden_2_layer = {'weights':\n                      tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl2]))}\n\n    hidden_3_layer = {'weights':\n                      tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl3]))}\n    \n    hidden_4_layer = {'weights':\n                      tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl4])),\n                      'biases':\n                      tf.Variable(tf.random_normal([n_nodes_hl4]))}\n\n    output_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl4,\n                                                             n_classes])),\n                    'biases': tf.Variable(tf.random_normal([n_classes]))}\n    print_shape(data)\n    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']),\n                hidden_1_layer['biases'])\n    print_shape(l1)\n    l1 = tf.nn.relu(l1)\n    print_shape(l1)\n    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']),\n                hidden_2_layer['biases'])\n    l2 = tf.nn.relu(l2)\n\n    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']),\n                hidden_3_layer['biases'])\n    l3 = tf.nn.relu(l3)\n\n    output = tf.add(tf.matmul(l3, output_layer['weights']),\n                    output_layer['biases'])\n    \n    l4 = tf.add(tf.matmul(l3, hidden_4_layer['weights']),\n               hidden_4_layer['biases'])\n    l4 = tf.nn.relu(l4)    \n\n    output = tf.add(tf.matmul(l4, output_layer['weights']),\n                   output_layer['biases'])\n    return output\n\n\ndef train_neural_network(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n                          (logits=prediction, labels=y))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n\n    hm_epochs = 10\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            for _ in range(int(mnist.train.num_examples / batch_size)):\n                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x,\n                                                              y: epoch_y})\n                epoch_loss += c\n            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:',\n                  epoch_loss)\n            \n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n        print('Accuracy:', accuracy.eval({x: mnist.test.images, y:\n                                          mnist.test.labels}))\n\n\ntrain_neural_network(x)", "cell_type": "code", "execution_count": 11, "outputs": [{"output_type": "stream", "name": "stdout", "text": "WARNING:tensorflow:From <ipython-input-11-a45e41f52a3d>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\nWARNING:tensorflow:From /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use urllib or similar directly.\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nWARNING:tensorflow:From /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting /tmp/data/train-images-idx3-ubyte.gz\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nWARNING:tensorflow:From /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting /tmp/data/train-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting /tmp/data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting /tmp/data/t10k-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n[None, 784]\n[None, 500]\n[None, 500]\nWARNING:tensorflow:From <ipython-input-11-a45e41f52a3d>:73: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n"}, {"output_type": "error", "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-11-a45e41f52a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m<ipython-input-11-a45e41f52a3d>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhm_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       raise TypeError(\n\u001b[0;32m--> 439\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    441\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."], "ename": "TypeError"}], "metadata": {"trusted": true}}, {"source": "def train_neural_network(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n                          (logits=prediction, labels=y))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n\n    hm_epochs = 10\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            for _ in range(int(mnist.train.num_examples / batch_size)):\n                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x,\n                                                              y: epoch_y})\n                epoch_loss += c\n            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:',\n                  epoch_loss)\n\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n        print('Accuracy:', accuracy.eval({x: mnist.test.images, y:\n                                          mnist.test.labels}))\n\n\ntrain_neural_network(x)", "cell_type": "code", "execution_count": 12, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[None, 784]\n[None, 500]\n[None, 500]\n"}, {"output_type": "error", "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-12-04c52882bf46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m<ipython-input-12-04c52882bf46>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhm_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       raise TypeError(\n\u001b[0;32m--> 439\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    441\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."], "ename": "TypeError"}], "metadata": {"trusted": true}}, {"source": "def optimize_model():\n    if len(memory) < BATCH_SIZE:\n        return\n    transitions = memory.sample(BATCH_SIZE)\n    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n    # detailed explanation).\n    batch = Transition(*zip(*transitions))\n\n    # Compute a mask of non-final states and concatenate the batch elements\n    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n                                          batch.next_state)), device=device, dtype=torch.uint8)\n    non_final_next_states = torch.cat([s for s in batch.next_state\n                                                if s is not None])\n    state_batch = torch.cat(batch.state)\n    action_batch = torch.cat(batch.action)\n    reward_batch = torch.cat(batch.reward)\n\n    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n    # columns of actions taken\n    state_action_values = policy_net(state_batch).gather(1, action_batch)\n\n    # Compute V(s_{t+1}) for all next states.\n    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n    # Compute the expected Q values\n    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n\n    # Compute Huber loss\n    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n\n    # Optimize the model\n    optimizer.zero_grad()\n    loss.backward()\n    for param in policy_net.parameters():\n        param.grad.data.clamp_(-1, 1)\n    optimizer.step()\n\nnum_episodes = 50\nfor i_episode in range(num_episodes):\n    # Initialize the environment and state\n    env.reset()\n    last_screen = get_screen()\n    current_screen = get_screen()\n    state = current_screen - last_screen\n    for t in count():\n        # Select and perform an action\n        action = select_action(state)\n        _, reward, done, _ = env.step(action.item())\n        reward = torch.tensor([reward], device=device)\n\n        # Observe new state\n        last_screen = current_screen\n        current_screen = get_screen()\n        if not done:\n            next_state = current_screen - last_screen\n        else:\n            next_state = None\n\n        # Store the transition in memory\n        memory.push(state, action, next_state, reward)\n\n        # Move to the next state\n        state = next_state\n\n        # Perform one step of the optimization (on the target network)\n        optimize_model()\n        if done:\n            episode_durations.append(t + 1)\n            plot_durations()\n            break\n    # Update the target network\n    if i_episode % TARGET_UPDATE == 0:\n        target_net.load_state_dict(policy_net.state_dict())\n\nprint('Complete')\nenv.render()\nenv.close()\nplt.ioff()\nplt.show()", "cell_type": "code", "execution_count": 13, "outputs": [{"output_type": "error", "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-13-22f5d9b04f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Initialize the environment and state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/mnt/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       raise TypeError(\n\u001b[0;32m--> 439\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    441\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."], "ename": "TypeError"}], "metadata": {"trusted": true}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"trusted": true}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython2", "version": "2.7.15", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}